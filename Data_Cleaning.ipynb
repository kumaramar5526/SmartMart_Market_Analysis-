{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning Pipeline for SmartMart"
      ],
      "metadata": {
        "id": "pkRy39YU0urd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "_eVnUQXb0RbW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load datasets"
      ],
      "metadata": {
        "id": "FSU2pBvm0-Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv(\"customers.csv\")\n",
        "products = pd.read_csv(\"products.csv\")\n",
        "sales = pd.read_csv(\"sales_transactions.csv\")\n",
        "stock = pd.read_csv(\"stock_levels.csv\")\n",
        "stores = pd.read_csv(\"stores.csv\")"
      ],
      "metadata": {
        "id": "oZY1cd4J0_R0"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Cleaning Functions"
      ],
      "metadata": {
        "id": "cr0JN5NE1ItS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataframe(df):\n",
        "    \"\"\"General cleaning: drop duplicates, strip spaces, standardize column names.\"\"\"\n",
        "    # Drop duplicates\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    # Strip spaces from column names\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Strip spaces from string columns\n",
        "    for col in df.select_dtypes(include=\"object\").columns:\n",
        "        df[col] = df[col].str.strip()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "mhiCxCIL1JhJ"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_missing_values(df):\n",
        "    \"\"\"Handle missing values with simple strategies.\"\"\"\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == \"object\":\n",
        "            df[col] = df[col].fillna(\"Unknown\")\n",
        "        else:\n",
        "            df[col] = df[col].fillna(df[col].median())  # median for numeric\n",
        "    return df"
      ],
      "metadata": {
        "id": "Ih8O9mn01UyS"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_text(df, columns):\n",
        "    \"\"\"Standardize categorical text columns (capitalize first letter).\"\"\"\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].str.capitalize()\n",
        "    return df"
      ],
      "metadata": {
        "id": "_3kEt4f21Wch"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Apply Cleaning"
      ],
      "metadata": {
        "id": "GueMl5Ng1h46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customers\n",
        "customers = clean_dataframe(customers)\n",
        "customers = fill_missing_values(customers)\n",
        "customers = standardize_text(customers, [\"gender\", \"city\", \"loyalty_member\"])"
      ],
      "metadata": {
        "id": "WFRRdqIp1jaq"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Products\n",
        "products = clean_dataframe(products)\n",
        "products = fill_missing_values(products)\n",
        "products = standardize_text(products, [\"category\", \"subcategory\"])"
      ],
      "metadata": {
        "id": "dcMxxj-B1ygS"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sales Transactions\n",
        "sales = clean_dataframe(sales)\n",
        "sales = fill_missing_values(sales)"
      ],
      "metadata": {
        "id": "ptZFQuyc1zX6"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date column to datetime (if exists)\n",
        "if \"transaction_date\" in sales.columns:\n",
        "    sales[\"transaction_date\"] = pd.to_datetime(sales[\"transaction_date\"])"
      ],
      "metadata": {
        "id": "f-5lvj9Y121Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3e5a35-9194-4b62-cbea-f6c5975fe2c1"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-296878576.py:3: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  sales[\"transaction_date\"] = pd.to_datetime(sales[\"transaction_date\"])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stock Levels\n",
        "stock = clean_dataframe(stock)\n",
        "stock = fill_missing_values(stock)"
      ],
      "metadata": {
        "id": "7B3iihJz15ZD"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stores\n",
        "stores = clean_dataframe(stores)\n",
        "stores = fill_missing_values(stores)\n",
        "stores = standardize_text(stores, [\"city\"])"
      ],
      "metadata": {
        "id": "9yka1-z51756"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Additional Preprocessing"
      ],
      "metadata": {
        "id": "N_bvbpp29333"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if customers['customer_id'].dtype == 'object':\n",
        "  customers['customer_id'] = customers['customer_id'].str.lstrip('CUST_').astype(int)\n",
        "if customers[\"loyalty_member\"].dtype != bool:\n",
        "  customers['loyalty_member'] = customers['loyalty_member'].replace({'Yes': True, 'No': False})\n",
        "  customers['loyalty_member'] = customers['loyalty_member'].astype(bool)\n",
        "customers = pd.get_dummies(customers, columns=['gender', 'city'], dtype=bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IYn31c899hn",
        "outputId": "2ee26021-da53-48e1-e338-0789424d7eeb"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-28362746.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  customers['loyalty_member'] = customers['loyalty_member'].replace({'Yes': True, 'No': False})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales['customer_id'] = sales['customer_id'].replace('Unknown', np.nan)\n",
        "if sales['customer_id'].dtype == 'object':\n",
        "  sales['customer_id'] = sales['customer_id'].str.lstrip('CUST_').astype(float)\n",
        "sales = pd.get_dummies(sales, columns=['store_id'], dtype=bool)"
      ],
      "metadata": {
        "id": "eV8jCaRkCLIy"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock = pd.get_dummies(stock, columns=['store_id'], dtype=bool)"
      ],
      "metadata": {
        "id": "PCUpzLP4J6lE"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores = pd.get_dummies(stores, columns=['store_id', 'store_format'], dtype=bool)"
      ],
      "metadata": {
        "id": "Cb5TTlntKMVK"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = pd.get_dummies(products, columns=['category'], dtype=bool)\n",
        "products = products.drop(columns=['product_name', 'unit_size'], axis=1)"
      ],
      "metadata": {
        "id": "kdECzq4NZBJV"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Save processed datasets"
      ],
      "metadata": {
        "id": "GgLCln-z2N37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content/cleaned_datasets\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "DKKVbhwS2O2K"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers.to_csv(f\"{output_dir}/customers_clean.csv\", index=False)\n",
        "products.to_csv(f\"{output_dir}/products_clean.csv\", index=False)\n",
        "sales.to_csv(f\"{output_dir}/sales_transactions_clean.csv\", index=False)\n",
        "stock.to_csv(f\"{output_dir}/stock_levels_clean.csv\", index=False)\n",
        "stores.to_csv(f\"{output_dir}/stores_clean.csv\", index=False)"
      ],
      "metadata": {
        "id": "ueN8ir0Q2Umx"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All cleaned datasets saved in:\", output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VN2vpXE2hsB",
        "outputId": "6fded44a-a24e-4a96-d419-e6e409a75b1d"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All cleaned datasets saved in: /content/cleaned_datasets\n"
          ]
        }
      ]
    }
  ]
}